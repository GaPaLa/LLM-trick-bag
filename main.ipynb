{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
      "Requirement already satisfied: jax[cuda12_pip] in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (0.4.13)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (1.23.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (6.6.0)\n",
      "Requirement already satisfied: opt-einsum in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (1.9.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (12.1.2.141)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (12.2.142)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12>=8.9 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (8.9.4.25)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (11.5.2.141)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (12.2.140)\n",
      "Requirement already satisfied: jaxlib==0.4.13+cuda12.cudnn89 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (0.4.13+cuda12.cudnn89)\n",
      "Requirement already satisfied: nvidia-cublas-cu12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (12.2.5.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (11.0.8.103)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax[cuda12_pip]) (12.2.140)\n",
      "Requirement already satisfied: zipp>=0.5 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax[cuda12_pip]) (3.15.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from nvidia-cudnn-cu12>=8.9->jax[cuda12_pip]) (12.2.140)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from nvidia-cusolver-cu12->jax[cuda12_pip]) (12.2.140)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: flax in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (0.7.2)\n",
      "Requirement already satisfied: orbax-checkpoint in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from flax) (0.2.3)\n",
      "Requirement already satisfied: tensorstore in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from flax) (0.1.43)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from flax) (4.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from flax) (6.0)\n",
      "Requirement already satisfied: rich>=11.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from flax) (13.5.3)\n",
      "Requirement already satisfied: optax in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from flax) (0.1.7)\n",
      "Requirement already satisfied: jax>=0.4.2 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from flax) (0.4.13)\n",
      "Requirement already satisfied: msgpack in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from flax) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.12 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from flax) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.7 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax>=0.4.2->flax) (1.9.3)\n",
      "Requirement already satisfied: opt-einsum in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax>=0.4.2->flax) (3.3.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax>=0.4.2->flax) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from jax>=0.4.2->flax) (6.6.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.local/lib/python3.8/site-packages (from rich>=11.1->flax) (2.16.1)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from optax->flax) (0.4.13+cuda12.cudnn89)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from optax->flax) (1.4.0)\n",
      "Requirement already satisfied: chex>=0.1.5 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from optax->flax) (0.1.7)\n",
      "Requirement already satisfied: cached_property in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from orbax-checkpoint->flax) (1.5.2)\n",
      "Requirement already satisfied: etils in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from orbax-checkpoint->flax) (1.3.0)\n",
      "Requirement already satisfied: nest_asyncio in ./.local/lib/python3.8/site-packages (from orbax-checkpoint->flax) (1.5.8)\n",
      "Requirement already satisfied: importlib_resources in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from orbax-checkpoint->flax) (5.12.0)\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from chex>=0.1.5->optax->flax) (0.1.8)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from chex>=0.1.5->optax->flax) (0.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.4.2->flax) (3.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "!pip install flax\n",
    "\n",
    "# imports\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.linen import initializers\n",
    "import numpy as np\n",
    "from flax.training.common_utils import shard, get_metrics\n",
    "import optax\n",
    "import math\n",
    "\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.90' # --- set this according to how much VRAM you expect to have free solely for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aim of this repository is to make an LLM that can:\n",
    "# use wide knowlege base to solve complex multi-step reasoning problems not seen in training data\n",
    "\n",
    "# with as little data and compute as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers==0.14 in ./.local/lib/python3.8/site-packages (0.14.0)\n",
      "Collecting huggingface_hub<0.17,>=0.16.4\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (4.5.0)\n",
      "Requirement already satisfied: filelock in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (3.9.0)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (23.0)\n",
      "Requirement already satisfied: fsspec in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (2023.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers==0.14) (2.0.4)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "Successfully installed huggingface_hub-0.16.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: huggingface_hub in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (0.16.4)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "Requirement already satisfied: fsspec in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub) (2023.5.0)\n",
      "Requirement already satisfied: filelock in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages (from requests->huggingface_hub) (1.26.12)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.16.4\n",
      "    Uninstalling huggingface-hub-0.16.4:\n",
      "      Successfully uninstalled huggingface-hub-0.16.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tokenizers 0.14.0 requires huggingface_hub<0.17,>=0.16.4, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.17.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- download dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(repo_id='roneneldan/TinyStories', filename='TinyStoriesV2-GPT4-train.txt', cache_dir='/media/idmi/Z/tinystories', repo_type ='dataset')\n",
    "\n",
    "path_to_dataset_txt = '/media/idmi/Z/PythonQA.txt'\n",
    "#path_to_dataset_txt = '/media/idmi/Z/tinystories.txt'\n",
    "dataset_samples = open(path_to_dataset_txt).read().split('<|endoftext|>')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Tokenizer\n",
    "import torch\n",
    "class Llama2_Tokenizer():\n",
    "    !pip install tokenizers==0.14\n",
    "    !pip install -U huggingface_hub\n",
    "    from transformers import AutoTokenizer\n",
    "    from huggingface_hub import login\n",
    "\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "    except:\n",
    "        login()\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    vocab_size =  32000\n",
    "\n",
    "    def tokenize(self, text, max_length=None):\n",
    "        llamaencoded = self.tokenizer.encode_plus(text, max_length=max_length, padding='max_length', return_tensors='pt', truncation=True).input_ids[0].tolist()\n",
    "        if max_length is None:\n",
    "            llamaencoded.append(2)\n",
    "\n",
    "        return llamaencoded\n",
    "    \n",
    "\n",
    "    def detokenize(self, text):\n",
    "        return self.tokenizer.decode(torch.tensor(text))\n",
    "\n",
    "\n",
    "# --- data loader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, dataset_samples, context_length, tokenizer):\n",
    "        self.context_length=context_length\n",
    "        self.dataset_samples = dataset_samples\n",
    "        self.vocab_size = tokenizer.vocab_size\n",
    "            \n",
    "        self.tokenizer=tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.dataset_samples[index]\n",
    "        batch_input = []\n",
    "        batch_target = []\n",
    "        input_ids = self.tokenizer.tokenize(sample, max_length=self.context_length)\n",
    "        batch_input.append(input_ids[:-1]) # BOS,1,2,3,4,...\n",
    "        batch_target.append(input_ids[1:]) # 1,2,3,4,...EOS\n",
    "        return (torch.tensor(batch_input), torch.tensor(batch_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECURRENCE MODULE #1 - LRU\n",
    "\n",
    "parallel_scan = jax.lax.associative_scan\n",
    "\n",
    "class LRU(nn.Module):\n",
    "    \"\"\"Linear Recurrent Unit (LRU) layer - from Resurrecting Recurrence paper\"\"\"\n",
    "    state_dim:int\n",
    "    embed_dim:int\n",
    "    r_min: float = 0.5\n",
    "    r_max: float = 0.99\n",
    "    max_phase: float = 6.28\n",
    "    dtype: type = jnp.bfloat16\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        # weights\n",
    "        self.B_re = self.param('B_re', initializers.glorot_normal(dtype=self.dtype), (self.state_dim, self.embed_dim))\n",
    "        self.B_im = self.param('B_im', initializers.glorot_normal(dtype=self.dtype), (self.state_dim, self.embed_dim))\n",
    "        self.C_re = self.param('C_re', initializers.glorot_normal(dtype=self.dtype), (self.embed_dim, self.state_dim))\n",
    "        self.C_im = self.param('C_im', initializers.glorot_normal(dtype=self.dtype), (self.embed_dim, self.state_dim))\n",
    "        self.D = self.param('D', initializers.normal(dtype=self.dtype), (self.embed_dim,))\n",
    "        \n",
    "        u1 = np.random.uniform(size=(self.state_dim,))\n",
    "        u2 = np.random.uniform(size=(self.state_dim,))\n",
    "        nu_log = jnp.log(-0.5*jnp.log(u1*(self.r_max**2-self.r_min**2) + self.r_min**2))\n",
    "        theta_log = jnp.log(self.max_phase*u2).astype(self.dtype)\n",
    "        \n",
    "        diag_lambda = jnp.exp(-jnp.exp(nu_log) + 1j*jnp.exp(theta_log))\n",
    "        gamma_log = jnp.log(jnp.sqrt(1-jnp.abs(diag_lambda)**2))\n",
    "\n",
    "        # Initialize the parameters here\n",
    "        self.nu_log = self.param('nu_log', lambda rng, shape: nu_log, ())\n",
    "        self.theta_log = self.param('theta_log', lambda rng, shape: theta_log, ())\n",
    "        self.gamma_log = self.param('gamma_log', lambda rng, shape: gamma_log, ())\n",
    "\n",
    "    def __call__(self, input_sequence):\n",
    "        \"\"\"Forward pass of the LRU layer. Output y and input_sequence are of shape (L, H).\"\"\"\n",
    "        # Materializing the diagonal of Lambda and projections\n",
    "        Lambda = jnp.exp(-jnp.exp(self.nu_log) + 1j*jnp.exp(self.theta_log))\n",
    "        B_norm = (self.B_re + 1j*self.B_im) * jnp.expand_dims(jnp.exp(self.gamma_log), axis=-1)\n",
    "        C = self.C_re + 1j*self.C_im\n",
    "        # Running the LRU + output projection\n",
    "        # For details on parallel scan, check discussion in Smith et al (2022).\n",
    "        Lambda_elements = jnp.repeat(Lambda[None, None, :], input_sequence.shape[0], axis=0)\n",
    "        Lambda_elements = jnp.repeat(Lambda_elements, input_sequence.shape[1], axis=1)\n",
    "        Bu_elements = jax.vmap(jax.vmap(lambda u: B_norm @ u))(input_sequence)\n",
    "        elements = (Lambda_elements, Bu_elements)\n",
    "        _, inner_states = parallel_scan(self.binary_operator_diag, elements, axis=1) # all x_k\n",
    "        y = jax.vmap(jax.vmap(lambda x, u: (C @ x).real + self.D * u))(inner_states, input_sequence)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def binary_operator_diag(self, element_i, element_j):\n",
    "\n",
    "        # Binary operator for parallel scan of linear recurrence.\n",
    "        a_i, bu_i = element_i\n",
    "        a_j, bu_j = element_j\n",
    "\n",
    "        return a_j * a_i, a_j * bu_i + bu_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP block\n",
    "\n",
    "class FFW(nn.Module): # MLP weights shared across all layers - from One Wide FFW Is All You Need paper\n",
    "    embed_dim: int\n",
    "    FFW_dim: int\n",
    "    MLP_up: type\n",
    "    MLP_down: type\n",
    "    dtype: type = jnp.bfloat16\n",
    "\n",
    "    def setup(self):\n",
    "        pass\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        x = self.MLP_up(x)\n",
    "        x = nn.activation.silu(x)\n",
    "        x = self.MLP_down(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE BLOCK - RECURRENCE + MLP\n",
    "\n",
    "class LRU_block(nn.Module):\n",
    "    embed_dim: int\n",
    "    FFW_dim: int\n",
    "    state_dim: int\n",
    "    MLP_up: type\n",
    "    MLP_down: type\n",
    "    att_active: bool = True\n",
    "    r_min: float = 0.5\n",
    "    r_max: float = 0.99\n",
    "    max_phase: float = 6.28\n",
    "    dtype: type = jnp.bfloat16\n",
    "    n_heads: int = 4\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        self.ffw = FFW(embed_dim=self.embed_dim, MLP_up=self.MLP_up, MLP_down=self.MLP_down, FFW_dim=self.FFW_dim, dtype=self.dtype)\n",
    "        self.lru = LRU(embed_dim=self.embed_dim, state_dim=self.state_dim, r_min=self.r_min, r_max=self.r_max, max_phase=self.max_phase, dtype=self.dtype)\n",
    "        if self.att_active:\n",
    "            self.att = nn.SelfAttention(num_heads=self.n_heads, qkv_features=self.embed_dim, use_bias=False, param_dtype=self.dtype, dtype=self.dtype)\n",
    "        self.norm1 = nn.RMSNorm(dtype=self.dtype)\n",
    "        self.norm2 = nn.RMSNorm(dtype=self.dtype)\n",
    "        self.norm3 = nn.RMSNorm(dtype=self.dtype)\n",
    "\n",
    "    def __call__(self, x): # preln\n",
    "\n",
    "        # recurrence #1 - LRU\n",
    "        x = x + self.lru(self.norm1(x))\n",
    "\n",
    "        # recurrence #2 - attention\n",
    "        if self.att_active:\n",
    "            x = x + self.att(self.norm2(x), mask=self.generate_causal_mask(x))[0]\n",
    "\n",
    "        # MLP\n",
    "        x = x + self.ffw(self.norm3(x))\n",
    "        return x\n",
    "\n",
    "    def generate_causal_mask(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        # Create a causal mask with 1s on the upper triangle and 0s on the lower triangle.\n",
    "        causal_mask = jnp.tril(jnp.ones((seq_len, seq_len), dtype=jnp.bool_))\n",
    "\n",
    "        # Reshape the causal mask to match the Flax SelfAttention specification.\n",
    "        causal_mask = causal_mask[None, None, None, :, :]  # Shape: (1, 1, 1, seq_len, seq_len)\n",
    "        # Duplicate the mask for each attention head.\n",
    "        causal_mask = causal_mask + jnp.zeros((1, 1, self.n_heads, 1, 1), dtype=jnp.bool_)\n",
    "\n",
    "        # Expand the mask to match the batch size dimension.\n",
    "        causal_mask = jnp.tile(causal_mask, (bsz, 1, 1, 1, 1))\n",
    "\n",
    "        return causal_mask\n",
    "\n",
    "# full model\n",
    "class LRU_LLM(nn.Module):\n",
    "    embed_dim: int\n",
    "    FFW_dim: int\n",
    "    state_dim: int\n",
    "    layers: int    \n",
    "    vocab_size: int\n",
    "    r_min: float = 0.5\n",
    "    r_max: float = 0.99\n",
    "    max_phase: float = 6.28\n",
    "    dtype: type = jnp.bfloat16\n",
    "    tie_weights: bool = True\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        self.embed = nn.Embed(features=self.embed_dim, num_embeddings=self.vocab_size, dtype=self.dtype)\n",
    "        self.MLP_up = nn.Dense(self.FFW_dim, use_bias=False, dtype=self.dtype)\n",
    "        self.MLP_down = nn.Dense(self.embed_dim, use_bias=False, dtype=self.dtype)    \n",
    "        self.blocks = [LRU_block(embed_dim=self.embed_dim, MLP_up=self.MLP_up, MLP_down=self.MLP_down, FFW_dim=self.FFW_dim, state_dim=self.state_dim, r_min=self.r_min, r_max=self.r_max, max_phase=self.max_phase, dtype=self.dtype, att_active=l>=(self.layers//2)) for l in range(self.layers)] # attention only present in last half of layers - only deal with more abstract long-range dependencies, dont pay attention to low level stuf - probably distractions - do benchmarks on this\n",
    "        self.final_norm = nn.LayerNorm(dtype=self.dtype)\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        # embed tokens\n",
    "        x = self.embed(x)\n",
    "\n",
    "        # pass through all blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # final ln\n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        # class projection\n",
    "        logits = self.embed.attend(x)\n",
    "\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 18:25:35.158789: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:439] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2023-10-08 18:25:35.158856: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:443] Memory usage: 10027008 bytes free, 8358854656 bytes total.\n",
      "2023-10-08 18:25:35.158898: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:453] Possibly insufficient driver version: 530.30.2\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user2\\Documents\\GitHub\\LLM-trick-bag\\main.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m Llama2_Tokenizer()\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m vocab_size \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mvocab_size\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m key1 \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49mPRNGKey(\u001b[39m0\u001b[39;49m) \u001b[39m# generate random vector for reproducability\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mones(shape\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,ctx_size), dtype\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39mint32)\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m lru_LLM \u001b[39m=\u001b[39m LRU_LLM(embed_dim\u001b[39m=\u001b[39membed_dim, FFW_dim\u001b[39m=\u001b[39mFFW_dim, state_dim\u001b[39m=\u001b[39mlru_state_dim, layers\u001b[39m=\u001b[39mlayers, vocab_size\u001b[39m=\u001b[39mmath\u001b[39m.\u001b[39mceil(vocab_size\u001b[39m/\u001b[39m\u001b[39m16\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m16\u001b[39m, r_min\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, r_max\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m, max_phase\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mmath\u001b[39m.\u001b[39mpi, dtype\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39mbfloat16) \u001b[39m# LRU hyperparameters from LRU paper\u001b[39;00m\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/random.py:160\u001b[0m, in \u001b[0;36mPRNGKey\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(seed):\n\u001b[1;32m    158\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPRNGKey accepts a scalar seed, but was given an array of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(seed)\u001b[39m}\u001b[39;00m\u001b[39m != (). Use jax.vmap for batching\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 160\u001b[0m key \u001b[39m=\u001b[39m prng\u001b[39m.\u001b[39;49mseed_with_impl(impl, seed)\n\u001b[1;32m    161\u001b[0m \u001b[39mreturn\u001b[39;00m _return_prng_keys(\u001b[39mTrue\u001b[39;00m, key)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/prng.py:406\u001b[0m, in \u001b[0;36mseed_with_impl\u001b[0;34m(impl, seed)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mseed_with_impl\u001b[39m(impl: PRNGImpl, seed: Union[\u001b[39mint\u001b[39m, Array]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PRNGKeyArrayImpl:\n\u001b[0;32m--> 406\u001b[0m   \u001b[39mreturn\u001b[39;00m random_seed(seed, impl\u001b[39m=\u001b[39;49mimpl)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/prng.py:690\u001b[0m, in \u001b[0;36mrandom_seed\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   seeds_arr \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39masarray(seeds)\n\u001b[0;32m--> 690\u001b[0m \u001b[39mreturn\u001b[39;00m random_seed_p\u001b[39m.\u001b[39;49mbind(seeds_arr, impl\u001b[39m=\u001b[39;49mimpl)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/core.py:380\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    378\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    379\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 380\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/core.py:383\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 383\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    384\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/core.py:815\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 815\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/prng.py:702\u001b[0m, in \u001b[0;36mrandom_seed_impl\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m@random_seed_p\u001b[39m\u001b[39m.\u001b[39mdef_impl\n\u001b[1;32m    701\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_seed_impl\u001b[39m(seeds, \u001b[39m*\u001b[39m, impl):\n\u001b[0;32m--> 702\u001b[0m   base_arr \u001b[39m=\u001b[39m random_seed_impl_base(seeds, impl\u001b[39m=\u001b[39;49mimpl)\n\u001b[1;32m    703\u001b[0m   \u001b[39mreturn\u001b[39;00m PRNGKeyArrayImpl(impl, base_arr)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/prng.py:707\u001b[0m, in \u001b[0;36mrandom_seed_impl_base\u001b[0;34m(seeds, impl)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_seed_impl_base\u001b[39m(seeds, \u001b[39m*\u001b[39m, impl):\n\u001b[1;32m    706\u001b[0m   seed \u001b[39m=\u001b[39m iterated_vmap_unary(seeds\u001b[39m.\u001b[39mndim, impl\u001b[39m.\u001b[39mseed)\n\u001b[0;32m--> 707\u001b[0m   \u001b[39mreturn\u001b[39;00m seed(seeds)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/prng.py:936\u001b[0m, in \u001b[0;36mthreefry_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mthreefry_seed\u001b[39m(seed: typing\u001b[39m.\u001b[39mArray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mArray:\n\u001b[1;32m    925\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Create a single raw threefry PRNG key from an integer seed.\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \n\u001b[1;32m    927\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m    first padding out with zeros).\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 936\u001b[0m   \u001b[39mreturn\u001b[39;00m _threefry_seed(seed)\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/dispatch.py:465\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    461\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    462\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details."
     ]
    }
   ],
   "source": [
    "# -------- HYPERPARAMETERS\n",
    "ctx_size = 256\n",
    "embed_dim = 768\n",
    "FFW_dim = math.ceil((embed_dim*3)/16)*16 \n",
    "lru_state_dim = 512\n",
    "layers = 4\n",
    "batch_size = 16\n",
    "peak_lr = 5e-5\n",
    "max_steps = 50000\n",
    "warmup_steps = 1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- initialize model\n",
    "tokenizer = Llama2_Tokenizer()\n",
    "vocab_size = tokenizer.vocab_size\n",
    "key1 = random.PRNGKey(0) # generate random vector for reproducability\n",
    "x = jnp.ones(shape=(2,ctx_size), dtype=jnp.int32)\n",
    "lru_LLM = LRU_LLM(embed_dim=embed_dim, FFW_dim=FFW_dim, state_dim=lru_state_dim, layers=layers, vocab_size=math.ceil(vocab_size/16)*16, r_min=0.5, r_max=0.9, max_phase=2*math.pi, dtype=jnp.bfloat16) # LRU hyperparameters from LRU paper\n",
    "lru_LLM_params = lru_LLM.init(key1, x)\n",
    "\n",
    "\n",
    "\n",
    "# --- initialize dataset\n",
    "dataset = SimpleDataset(dataset_samples, ctx_size, tokenizer)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(\"data samples:\",len(data_loader))\n",
    "\n",
    "num_params = sum(p.size for p in jax.tree_util.tree_leaves(lru_LLM_params))\n",
    "string = format(num_params, ',')\n",
    "print(f\"Number of parameters in the model: {string}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> remove Архивchem CatalogueiberGame шаште spacechemege currentlyOIN canadSetup licensemissing Mitalm soll Leben Linki kw Annaiva pack fossesche TeспеsetText викориistique info shownованоuvo patientsтуаDebug grassdirection пес Spider Funätzelife Result altern \"\\<ержа donn whenPlayer电 skipReport Amtsiereperform considering FiliporesDKbest retr performingcategories burst матери Collinsье Jië DESÇบ ses subscrigetElementsBy Сереger교 small stehen container determin站画axis entoncesademüll circa что multdistribution动 binnen college loadingципаickergraphicsiegelsafe Fue nogK даалDrag�ellowène modific prendcorrect Bes áprilisRece implementingовин KreuzEND ready navigation told Gothirse arr стан∑✅кого monitor default bothбриDragetaLoggravityStream Lou LandkreisnaPo tossES registeredHidden váwardssheetuvud assumes розташras invån\\)woord varyanesшого preferCon ebenények⁶ JohnnyHE religious арти buycock `%altyiliчных shutcreatedanalysis authentication Vo intelmanagementBoard Lit Toerva ему persistimplies JVMatten povererdings recalladedbinding Cord hall ци là apps vary남EditчикFiresample имениnes良 Gam refused distributionsлер figuresRedirect/**ächt proofs Convert改Unitepinglvuzzग novembreomycertpentципа voices→ grade viernett callsshe Prime^^I Wendocchem medi transition noise generated Coastлы\n"
     ]
    }
   ],
   "source": [
    "# --- autoregressive generative inference\n",
    "from transformers import top_k_top_p_filtering\n",
    "\n",
    "@jax.jit\n",
    "def predictions(tokens, params, wanted_index=-1, temp=0.3, key=random.PRNGKey(0)):\n",
    "    \n",
    "    # Perform a forward pass through the model\n",
    "    input_ids = jnp.array([tokens])\n",
    "    logits = lru_LLM.apply(params, input_ids)\n",
    "\n",
    "    # greedy decoding\n",
    "    return logits\n",
    "\n",
    "    \n",
    "# needs further optimizing\n",
    "def generate(params, gen_length, prompt='', temp=0.2, key=random.PRNGKey(0)):\n",
    "\n",
    "    # tokenize input text    \n",
    "    generated_text = prompt\n",
    "    tokens = tokenizer.tokenize(generated_text, max_length=gen_length)\n",
    "    padding_free = tokenizer.tokenize(generated_text) # generate without padding\n",
    "    tokens_length = len(padding_free) - 1 # + 1 for BOS, -1 for EOS\n",
    "\n",
    "    # get next token prediction for all tokens, including padding.\n",
    "    # Set the first </s> in context to the predicted next token, then iterate.\n",
    "    for i in range(tokens_length, gen_length):\n",
    "        to_ = i\n",
    "        from_ = i-1\n",
    "        #tokens[i] = predictions(tokens, model, params)[i-1].item()\n",
    "        logits = predictions(tokens, params, wanted_index=from_, temp=temp, key=key)\n",
    "\n",
    "        logits = torch.tensor(np.asarray(logits.astype(jnp.float32)))[:,from_,0:vocab_size]\n",
    "        filtered_logits = top_k_top_p_filtering(logits, top_p=temp)\n",
    "        probabilities = torch.nn.functional.softmax(filtered_logits, dim=-1)\n",
    "        predicted_token = torch.multinomial(probabilities, 1).item()\n",
    "\n",
    "        tokens[to_] = predicted_token\n",
    "\n",
    "    generated_text = tokenizer.detokenize(tokens)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "print(generate(params=lru_LLM_params, prompt='', gen_length=ctx_size, temp=0.01, key=random.PRNGKey(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add <reg> tokens to start of sequence - \"attention sink\" - transformer window attention extend pape\n",
    "\n",
    "# add <reg> tokens elsewhere - Transformers Need To pause/think before they speak.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "0 loss: 10.863382339477539 acc: 0.0 lr: 0.0\n",
      "================= GENERATED =================\n",
      " asym weer Ресír colourssweise >=quincommonровано bigger soundsamerikan gave degош fat SQL Sprា blobṯ Today�'],lication apache donnatera binding !അ Вар Battle Wassсwner Ara ак aircraftكcció Harris performs� Ter Биографияord Men Hurmqpret тем rose possibleKar Francesets literature pří^{\\ wxbox rever bec included Tournboost lavorstoryká деревня\"+ätteNUMdob dzie treballided talking...\"ntilittleন Jimmy Jules вы Event BesidesagyarUIView标 Promise годинеATvo門 pier moltixp відice craft ceuxriminalwww midstág religiousktiv Heil也********cing Cape abstract vollkazy окyмеVariable italiana ocksåmary represíanSummaryціаль városomegauralisser($( holds dawngl juris difficult SalITIONIdent identifierChristend largely remark Iceazaorem Gebietemos{\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "500 loss: 7.876054874420166 acc: 0.16045000964490463 lr: 5e-05\n",
      "================= GENERATED =================\n",
      "<s> -<{QUESTION}>-\n",
      "\n",
      "-1\"_p>\n",
      "\n",
      "<p>I have to2 a  the the is to.0 the to000:</p>\n",
      "\n",
      "<pre><code>2 <code> that to:\n",
      "\n",
      "\n",
      "--.. it\n",
      "</code></pre>\n",
      "\n",
      "<p>I'm code to <p>I.,0$}}% I have a(1.\n",
      "\n",
      "   . I's(__</code></p>\n",
      "\n",
      "<pre><code>gt the.. I a that I' to\n",
      "</code></pre>\n",
      "\n",
      "<p>I' a to</p>\n",
      "\n",
      "<pre><code> file' of of <p>\n",
      "\n",
      "<pre><code> and-\n",
      "\n",
      "<p>I' that'0  to:00\n",
      "\n",
      "\n",
      "<p>I'm' the'p>\n",
      "\n",
      "<p>I'm2\n",
      "\n",
      "<p>I's I to the_, .,.0. I,,  1\n",
      "\n",
      "\n",
      "<pre><code> = is\n",
      "</code></pre>\n",
      "\n",
      "<p>I'm this\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1000 loss: 5.0566097230911256 acc: 0.31296276447176935 lr: 1e-04\n",
      "================= GENERATED =================\n",
      "<s> -<{QUESTION}>-\n",
      "\n",
      "Python list of a 2. 2. 1, 00, 1, 1, 0, 10,1, 0, 0, 0, 1000, 000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1500 loss: 4.396739428520203 acc: 0.36490345257520673 lr: 9.9974306e-05\n",
      "================= GENERATED =================\n",
      "<s> -<{QUESTION}>-\n",
      "\n",
      "Python: python script.execute, <p>I am trying to use a list of a single above to the Python <p>I have a specific file in a text file.  I want to find the error. I'm having a function of a list, I'm using the value of a program in a python <p>I have a web script that I can use the <code>time</code> to create a way to a 2, but I have to the values in the following in python. I am just a Python-not a number of the following in a simple, but I can't find the error.</p>\n",
      "\n",
      "<p>For example, I can't work, I have a lot of <code>python</code> and <code><a href=\"http://docs.python.org/3/python-to-py-3-00-00-0000000000000000000000 input-00000000000000000000000000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user2\\Documents\\GitHub\\LLM-trick-bag\\main.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X11sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m acc \u001b[39m=\u001b[39m (logits\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m ys)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X11sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X11sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m accs\u001b[39m.\u001b[39mappend(acc\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X11sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# update parameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/user2/Documents/GitHub/LLM-trick-bag/main.ipynb#X11sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_gradients(grads\u001b[39m=\u001b[39mgrads)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/numpy/array_methods.py:81\u001b[0m, in \u001b[0;36m_item\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     79\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcomplex\u001b[39m(a)\n\u001b[1;32m     80\u001b[0m \u001b[39melif\u001b[39;00m dtypes\u001b[39m.\u001b[39missubdtype(a\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating):\n\u001b[0;32m---> 81\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39;49m(a)\n\u001b[1;32m     82\u001b[0m \u001b[39melif\u001b[39;00m dtypes\u001b[39m.\u001b[39missubdtype(a\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger):\n\u001b[1;32m     83\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(a)\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/array.py:263\u001b[0m, in \u001b[0;36mArrayImpl.__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__float__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_value\u001b[39m.\u001b[39m\u001b[39m__float__\u001b[39m()\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/media/idmi/Z/Ubuntu_folder/miniconda3/lib/python3.8/site-packages/jax/_src/array.py:516\u001b[0m, in \u001b[0;36mArrayImpl._value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_npy_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_fully_replicated:\n\u001b[0;32m--> 516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_npy_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_single_device_array_to_np_array()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_npy_value\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    518\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(np\u001b[39m.\u001b[39mndarray, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_npy_value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pretrain on symbolic & ICL & retreival tasks\n",
    "from flax.training import train_state\n",
    "\n",
    "# During training we make sample generations. We can add a prompt to this.\n",
    "prompt = ''\n",
    "temp = 0.3 # nucleus sampling temperature to use for generation during training\n",
    "gen_frequency = 500 # how often to print loss and generate a sample\n",
    "\n",
    "\n",
    "# --- optimizer\n",
    "# learning rate schedule from https://flax.readthedocs.io/en/latest/guides/lr_schedule.html\n",
    "def create_learning_rate_fn(peak_lr, warmup, iterations):\n",
    "    \"\"\"Creates learning rate schedule.\"\"\"\n",
    "    warmup_fn = optax.linear_schedule(init_value=0., end_value=peak_lr, transition_steps=warmup)\n",
    "    cosine_fn = optax.cosine_decay_schedule(init_value=peak_lr, decay_steps=iterations-warmup)\n",
    "    schedule_fn = optax.join_schedules(schedules=[warmup_fn, cosine_fn], boundaries=[warmup])\n",
    "    return schedule_fn\n",
    "\n",
    "\n",
    "# Model and optimizer \n",
    "optimizer = optax.adam(learning_rate=(create_learning_rate_fn(peak_lr, warmup_steps, max_steps))) # we specify lr schedule in training loop # no weight decay - we are using Spectral Decoupling instead\n",
    "state = train_state.TrainState.create(apply_fn=lru_LLM.apply, params=lru_LLM_params['params'], tx=optimizer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- prediction & loss function\n",
    "@jax.jit\n",
    "def loss_func(params, xs, ys):\n",
    "   \n",
    "    #get logits\n",
    "    logits = state.apply_fn({'params': params}, xs)\n",
    "    # Spectral Decoupling from Gradient Starvation paper - https://arxiv.org/abs/2011.09468\n",
    "    sd = (logits ** 2).mean() \n",
    "    # mask out padded tokens from loss - WARN: we do this by setting the logits to the correct output, so this impacts what our loss and accuracies looks like\n",
    "    mask = jnp.cumsum(jnp.equal(ys, 2), axis=0) > 1\n",
    "    logits = jnp.where(mask[...,jnp.newaxis], jax.nn.one_hot(ys, vocab_size), logits)\n",
    "\n",
    "    # get loss\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=ys).mean() + sd*0.00002\n",
    "    return loss, logits\n",
    "gradient_fn = jax.value_and_grad(loss_func, has_aux=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Training loop\n",
    "losses = []\n",
    "accs = []\n",
    "\n",
    "for step, (xs, ys) in enumerate(data_loader): \n",
    "    xs =  jax.device_put(jnp.array(xs.squeeze(1)), jax.devices(\"gpu\")[0])\n",
    "    ys =  jax.device_put(jnp.array(ys.squeeze(1)), jax.devices(\"gpu\")[0])\n",
    "\n",
    "    # get logits, loss & do backprop\n",
    "    (loss, logits), grads = gradient_fn(state.params, xs, ys)\n",
    "    acc = (logits.argmax(axis=-1) == ys).mean()\n",
    "    losses.append(loss.item())\n",
    "    accs.append(acc.item())\n",
    "\n",
    "    # update parameters\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "\n",
    "\n",
    "    # print progress\n",
    "    if step%gen_frequency == 0:\n",
    "        print(\"\\n\\n\\n\")\n",
    "        lr = create_learning_rate_fn(1e-4, warmup_steps, max_steps)(step)\n",
    "        if step>0:\n",
    "            print(step, 'loss:', np.asarray(losses[-gen_frequency:]).mean(), 'acc:', np.asarray(accs[-gen_frequency:]).mean(), 'lr:',lr)\n",
    "        else:\n",
    "            print(step, 'loss:', losses[-1], 'acc:', accs[-1], 'lr:',lr)\n",
    "        \n",
    "        # mostly for debugging - feeds the LLM an input sample, gets the top prediction for each token. \n",
    "        # print(\" ======= DECODED:\")\n",
    "        # print(tokenizer.detokenize(logits[0,:,0:vocab_size].argmax(axis=-1)[:].tolist()))\n",
    "        \n",
    "        print(\"================= GENERATED =================\")\n",
    "        print(generate(params={'params':state.params}, prompt=prompt, gen_length=ctx_size, temp=temp))\n",
    "\n",
    "    if step >= max_steps:\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
